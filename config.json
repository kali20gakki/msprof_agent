{
  "llm": {
    "provider": "openai",
    "api_key": "sk-83ebf0ecded644cab66eb3eabd3951ce",
    "base_url": "http://127.0.0.1:8045/v1",
    "model": "gemini-3-flash",
    "temperature": 0,
    "max_tokens": 200000
  },
  "mcp_servers": [
    {
      "name": "msprof-mcp",
      "command": "uv",
      "args": [
        "tool",
        "run",
        "msprof-mcp"
      ],
      "env": {},
      "enabled": true
    }
  ],
  "theme": "dark"
}